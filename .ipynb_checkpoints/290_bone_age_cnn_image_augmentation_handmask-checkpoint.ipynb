{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings; warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import utils\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "import torch.nn.init as init\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the dataset and find the path of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boneage</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, boneage, male]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicates, no duplicates found\n",
    "train_df[train_df.duplicated(keep = False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>male</th>\n",
       "      <th>boneage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, male, boneage]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicates, no duplicates found\n",
    "test_df[test_df.duplicated(keep = False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image file directory\n",
    "img_dir = r'C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Training Set'\n",
    "test_img_dir = r'C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Test Set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_filepath(name, folder=img_dir):\n",
    "    path = os.path.join(folder, f'{name}.png')\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# find the file path for each image\n",
    "train_df['image_path'] = train_df.iloc[:, 0].apply(lambda x: return_filepath(x))\n",
    "test_df['image_path'] = test_df.iloc[:, 0].apply(lambda x: return_filepath(x, test_img_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['male'] = train_df['male'].astype(int)\n",
    "test_df['male'] = test_df['male'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boneage</th>\n",
       "      <th>male</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1377</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1378</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1379</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1380</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1381</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1382</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1383</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1384</td>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1385</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1387</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  boneage  male                                         image_path\n",
       "0  1377      180     0  C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Tr...\n",
       "1  1378       12     0  C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Tr...\n",
       "2  1379       94     0  C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Tr...\n",
       "3  1380      120     1  C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Tr...\n",
       "4  1381       82     0  C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Tr...\n",
       "5  1382      138     1  C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Tr...\n",
       "6  1383      150     1  C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Tr...\n",
       "7  1384      156     1  C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Tr...\n",
       "8  1385       36     1  C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Tr...\n",
       "9  1387      138     1  C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Tr..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>male</th>\n",
       "      <th>boneage</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1386</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1392</td>\n",
       "      <td>1</td>\n",
       "      <td>162</td>\n",
       "      <td>C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1397</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1401</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1410</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Te...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  male  boneage                                         image_path\n",
       "0  1386     0       30  C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Te...\n",
       "1  1392     1      162  C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Te...\n",
       "2  1397     0       18  C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Te...\n",
       "3  1401     0      132  C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Te...\n",
       "4  1410     1       57  C:\\Users\\stron\\Desktop\\290 Project\\Bone Age Te..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a CLAHE object\n",
    "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadiologyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, images_filepaths, male_features, bone_ages, transform):\n",
    "        self.images_filepaths = images_filepaths\n",
    "        self.male_features = male_features\n",
    "        self.bone_ages = bone_ages\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.images_filepaths[idx]        \n",
    "        img_cv2 = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB) # only this method read the image as black/white\n",
    "        \n",
    "        # Convert the color image to LAB color space. \n",
    "        # Lab color space is a 3-axis color system with dimension L for lightness and a and b for the color dimensions.\n",
    "        lab_image = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)\n",
    "        # Apply CLAHE to the L channel. L represents lightness from black to white on a scale of zero to 100\n",
    "        lab_image[:, :, 0] = clahe.apply(lab_image[:, :, 0])\n",
    "        # Convert back to RGB color space\n",
    "        enhanced_image = cv2.cvtColor(lab_image, cv2.COLOR_LAB2RGB)\n",
    "        \n",
    "        # Apply Gaussian blur to the image to reduce noise\n",
    "        blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "        # Apply adaptive thresholding to create a binary mask\n",
    "        binary_mask = cv2.adaptiveThreshold(blurred_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "        # Find contours in the binary mask\n",
    "        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        # Create an empty mask with the same size as the original image\n",
    "        hand_mask = np.zeros_like(xray_image)\n",
    "        \n",
    "        # Draw the largest contour (assumed to be the hand) on the mask\n",
    "        if contours:\n",
    "            largest_contour = max(contours, key=cv2.contourArea)\n",
    "            cv2.drawContours(hand_mask, [largest_contour], 0, 255, thickness=cv2.FILLED)\n",
    "\n",
    "        # Apply the hand mask to the original image\n",
    "        hand_extraction_result = cv2.bitwise_and(image, hand_mask)\n",
    "      \n",
    "        image = self.transform(hand_extraction_result)\n",
    "        male = self.male_features[idx]\n",
    "        label = torch.tensor(self.bone_ages[idx])\n",
    "        return image, male, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranformation that converts images into tensors\n",
    "img_transformer = transforms.Compose([transforms.ToTensor(),\n",
    "                                      transforms.CenterCrop((2000, 1200)),\n",
    "                                      transforms.Resize((512,512)),\n",
    "                                      transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                      transforms.RandomRotation(degrees=30),\n",
    "                                      transforms.ColorJitter(brightness=0.2, contrast=0.5, saturation=0.2, hue=0.5),\n",
    "                                      #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                                      #transforms.Lambda(lambda img: crop_blank(img)),\n",
    "                                      #transforms.RandomCrop((512,512), padding=None, pad_if_needed=False, fill=0, padding_mode='constant'),  \n",
    "                                      #transforms.FiveCrop(2000),\n",
    "                                      #transforms.RandomResizedCrop(size=(224, 224), antialias=True),\n",
    "                                      #transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "                                      #transforms.RandomVerticalFlip(p=0.5),\n",
    "                                      #transforms.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=10),\n",
    "                                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train df\n",
    "X_train = train_df['image_path']\n",
    "X_train_male = train_df['male'] # important feature in predicting bone age\n",
    "y_train = train_df['boneage'] # do we need to normalize the bone age?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "train_dataset = RadiologyDataset(\n",
    "    images_filepaths = X_train.values,\n",
    "    male_features = X_train_male.values,\n",
    "    bone_ages = y_train.values,\n",
    "    transform = img_transformer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test df\n",
    "X_test = test_df['image_path']\n",
    "X_test_male = test_df['male'] # important feature in predicting bone age\n",
    "y_test = test_df['boneage'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "test_dataset = RadiologyDataset(\n",
    "    images_filepaths = X_test.values,\n",
    "    male_features = X_test_male.values,\n",
    "    bone_ages = y_test.values,\n",
    "    transform = img_transformer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\thresh.cpp:1674: error: (-215:Assertion failed) src.type() == CV_8UC1 in function 'cv::adaptiveThreshold'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17560\\641023501.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# an example tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17560\\3814140451.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mblurred_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# Apply adaptive thresholding to create a binary mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mbinary_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madaptiveThreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblurred_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mADAPTIVE_THRESH_GAUSSIAN_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;31m# Find contours in the binary mask\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mcontours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETR_EXTERNAL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHAIN_APPROX_SIMPLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\thresh.cpp:1674: error: (-215:Assertion failed) src.type() == CV_8UC1 in function 'cv::adaptiveThreshold'\n"
     ]
    }
   ],
   "source": [
    "# an example tensor\n",
    "img, male, label = train_dataset[9]\n",
    "print(img.shape,torch.min(img),torch.max(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check the test set\n",
    "img, male, label = test_dataset[9]\n",
    "print(img.shape,torch.min(img),torch.max(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_img(train_dataset_p = train_dataset, inline=5):\n",
    "    plt.figure(figsize=(20,10))\n",
    "    j = 0\n",
    "    for i in range(inline):\n",
    "        image, dense, label = train_dataset_p[j]\n",
    "        plt.subplot(1, inline, i%inline+1)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image.permute(2, 1, 0))\n",
    "        plt.title(f'Bone Age: {label}')\n",
    "        j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_img(inline = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train validation split\n",
    "len_img = len(train_dataset)\n",
    "len_train = len_img - 700\n",
    "len_val = 700\n",
    "\n",
    "# split the tensor\n",
    "train_dataset, val_dataset = random_split(train_dataset, [len_train, len_val]) # validation size 0.25?\n",
    "\n",
    "print(\"train dataset size:\", len(train_dataset))\n",
    "print(\"validation dataset size:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "train_val_batch_size = 32\n",
    "test_batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size = train_val_batch_size, shuffle = True, num_workers = 0)\n",
    "val_loader = DataLoader(val_dataset, batch_size = train_val_batch_size, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size = test_batch_size, num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001 # learning rate\n",
    "\n",
    "# Define the neural network \n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64*64*64+1, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x, male):\n",
    "        x = self.pool1(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool2(nn.functional.relu(self.conv2(x)))\n",
    "        x = self.pool3(nn.functional.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64*64*64) # reshape\n",
    "        x = torch.cat([x, male.unsqueeze(1)], dim=1)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = nn.functional.relu(self.fc3(x))\n",
    "        x = nn.functional.relu(self.fc4(x))\n",
    "        x = nn.functional.relu(self.fc5(x))\n",
    "        return x\n",
    "\n",
    "model = Network()\n",
    "\n",
    "# initialization\n",
    "for name, param in model.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        init.kaiming_uniform_(param)\n",
    "    elif 'bias' in name:\n",
    "        init.constant_(param, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torchvision.models as models\n",
    "# Load pre-trained ResNet model\n",
    "#resnet_model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the output layer to match the number of classes in your problem\n",
    "#resnet_model.fc = nn.Linear(resnet18.fc.in_features, 1)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "#criterion = nn.MSELoss()\n",
    "#optimizer = torch.optim.Adam(resnet18.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "#num_epochs = 10\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#resnet_model.to(device)\n",
    "\n",
    "#for epoch in range(num_epochs):\n",
    "    #for inputs, males, labels in train_loader:\n",
    "        #inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        #outputs = resnet_model(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        #loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        #optimizer.zero_grad()\n",
    "        #loss.backward()\n",
    "        #optimizer.step()\n",
    "\n",
    "    #print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "\n",
    "# Save the trained model\n",
    "#torch.save(resnet_model.state_dict(), 'bone_age_resnet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define your execution device \n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to save the model\n",
    "def model_save():\n",
    "    path = './nn_model_290_2.pth'\n",
    "    torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function L2\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_temp = time.time()\n",
    "train_loader = list(train_loader)\n",
    "print(time.time()-t_temp)\n",
    "#t_temp = time.time()\n",
    "#val_loader = list(val_loader)\n",
    "#print(time.time()-t_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "min_valid_loss = np.inf\n",
    "tic = time.time()\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_loss = 0.0\n",
    "    for data in train_loader:\n",
    "        image, male, labels = data\n",
    "        image = image.cuda()\n",
    "        male = male.cuda()\n",
    "        labels = labels.unsqueeze(1).float()\n",
    "        labels = labels.cuda()\n",
    "    \n",
    "        optimizer.zero_grad() # zero the parameter gradients\n",
    "        target = model(image, male)\n",
    "        loss = loss_fn(target, labels)\n",
    "        loss.backward() # backpropagate the loss\n",
    "        optimizer.step() # adjust the parameters\n",
    "        train_loss += loss.item() # track the loss value\n",
    "    \n",
    "    # calculate the training loss value\n",
    "    train_loss_value = train_loss / len(train_loader)\n",
    "     \n",
    "    valid_loss = 0.0\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    y_actual = []\n",
    "    for data in val_loader:\n",
    "        image, male, labels = data\n",
    "        image = image.cuda()\n",
    "        male = male.cuda()\n",
    "        labels = labels.unsqueeze(1).float()\n",
    "        labels = labels.cuda()\n",
    "        \n",
    "        target = model(image, male)\n",
    "        loss = loss_fn(target,labels)\n",
    "        valid_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(image, male)\n",
    "            preds.append(output.cpu())\n",
    "            y_actual.append(labels.cpu())\n",
    "        \n",
    "    # calculate the validation loss value\n",
    "    val_loss_value = valid_loss / len(val_loader)\n",
    "    \n",
    "    # calculate the validation mae\n",
    "    preds = torch.cat(preds)\n",
    "    preds_processed = np.array(preds.reshape(-1))\n",
    "    y_actual = torch.cat(y_actual)\n",
    "    y_actual_processed = np.array(y_actual.reshape(-1))\n",
    "    val_mae = mean_absolute_error(y_actual_processed, preds_processed)\n",
    "    \n",
    "    # Save the model\n",
    "    if min_valid_loss > valid_loss:\n",
    "        min_valid_loss = valid_loss\n",
    "        model_save()\n",
    "        \n",
    "    print('Completed training batch', epoch, 'Training Loss is: %.4f' %train_loss_value, 'Validation Loss is: %.4f' %val_loss_value, 'Validation MAE is: %.4f' %val_mae)\n",
    "\n",
    "tac = time.time()\n",
    "print('Run time: ', round((tac - tic) / 60, 2), ' min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "preds = []\n",
    "for data in tqdm(test_loader):\n",
    "    image, male, labels = data\n",
    "    image = image.cuda()\n",
    "    male = male.cuda()\n",
    "    labels = labels.cuda()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(image, male)\n",
    "        preds.append(output.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = torch.cat(preds)\n",
    "print(preds.shape)\n",
    "preds_processed = np.array(preds.reshape(-1))\n",
    "print(len(preds_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('MAE: ', mean_absolute_error(y_test, preds_processed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
